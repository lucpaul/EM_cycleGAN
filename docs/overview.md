## Overview of Code Structure
To help users better understand and use codebase, we briefly overview the functionality and implementation of each package and each module. Please see the documentation in each file for more details. If you have questions, you may find useful information in [training/test tips](tips.md) and [frequently asked questions](qa.md).

[train.py](../train.py) is a general-purpose training script. It works for different model backbones (using the `--netG` flag with arguments such as `unet_32` for a 5 layer Unet, or `resnet_9blocks`). The dimension of the model can be set using `--train_mode` as `2d` or `3d`. See the main [README](.../README.md) and [training/test  tips](tips.md) for more details.

**We have added several new test scripts:**

[test_2D.py](../test_2D.py) is a test script for 2D Unet models. Once you have trained your model with `train.py` in `--train_mode 2d` and `--netG unet_...`, you can use this script to test the model, using the flag `--test_mode 2d`. It will load a saved model from `--name` and save the results to `--results_dir`. See the main [README](.../README.md) and [training/test tips](tips.md) for more details.

[test_3D.py](../test_3D.py) is a test script for 3D Unet models. Once you have trained your model with `train.py` in `--train_mode 3d` and `--netG unet_...`, you can use this script to test the model, using the flag `--test_mode 3d`.

[test_2D_resnet.py](../test_2D_resnet.py) is a test script for 2D models that do not have a unet backbone. Once you have trained your model with `train.py` in `train_mode 2d`, you can use this script to test the model, using the flag `--test_mode 2d`.

[test_3D_resnet.py](../test_3D_resnet.py) is a test script for 2D models that do not have a unet backbone. Once you have trained your model with `train.py` in `train_mode 3d`, you can use this script to test the model, using the flag `--test_mode 3d`.

[test_2_5D.py](../test_2_5D.py) is a test script for 2D Unet models. Once you have trained your model with `train.py` in `--train_mode 2d` and `--netG unet_...`, you can use this script to test the model, using the flag `--test_mode 2.5d`.

[test_2_5D_resnet.py](../test_2_5D_resnet.py) is a test script for 2D models that do not have a unet backbone. Once you have trained your model with `train.py` in `train_mode 2d`, you can use this script to test the model, using the flag `--test_mode 2.5d`.



[data](../data) directory contains all the modules related to data loading and preprocessing. To add a custom dataset class called `dummy`, you need to add a file called `dummy_dataset.py` and define a subclass `DummyDataset` inherited from `BaseDataset`. You need to implement four functions: `__init__` (initialize the class, you need to first call `BaseDataset.__init__(self, opt)`), `__len__` (return the size of dataset), `__getitem__`ã€€(get a data point), and optionally `modify_commandline_options` (add dataset-specific options and set default options). Now you can use the dataset class by specifying flag `--dataset_mode dummy`. See our template dataset [class](../data/template_dataset.py) for an example.   Below we explain each file in details.

* [\_\_init\_\_.py](../data/__init__.py) implements the interface between this package and training and test scripts. `train.py` and `test.py` call `from data import create_dataset` and `dataset = create_dataset(opt)` to create a dataset given the option `opt`.
* [base_dataset_2d.py](../data/base_dataset_2d.py) implements an abstract base class ([ABC](https://docs.python.org/3/library/abc.html)) for 2d datasets. It also includes common transformation functions (e.g., `get_transform`, `__scale_width`), which can be later used in subclasses.
* [base_dataset_3d.py](../data/base_dataset_3d.py) implements an abstract base class ([ABC](https://docs.python.org/3/library/abc.html)) for 3d datasets. It also includes common transformation functions (e.g., `get_transform`, `__scale_width`), which can be later used in subclasses.
* [image_folder.py](../data/image_folder.py) implements an image folder class. We modify the official PyTorch image folder [code](https://github.com/pytorch/vision/blob/master/torchvision/datasets/folder.py) so that this class can load images from both the current directory and its subdirectories.
* [template_dataset.py](../data/template_dataset.py) provides a dataset template with detailed documentation. Check out this file if you plan to implement your own dataset.
* [patched_2d_dataset.py](../data/patched_2d_dataset.py) includes a dataset class that loads 2d patches from an input dataset for inference. It assumes a single image directory `/path/to/data/test`, which contains image stacks from an image domain A. See [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/tips.md#prepare-your-own-datasets-for-pix2pix) on how to prepare aligned datasets.
* [patched_3d_dataset.py](../data/patched_3d_dataset.py) includes a dataset class that loads 3d patches from an input dataset for inference. It assumes a single image directory `/path/to/data/test`, which contains image stacks from an image domain A. See [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/tips.md#prepare-your-own-datasets-for-pix2pix) on how to prepare aligned datasets.
* [patched_2_5d_dataset.py](../data/patched_2_5d_dataset.py) includes a dataset class loads 2d patches from 3 different directions of the image stack, for inference. It assumes a single image directory `/path/to/data/test`, which contains image stacks from image domain A. See [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/tips.md#prepare-your-own-datasets-for-pix2pix) on how to prepare aligned datasets.
* [patched_unaligned_2d_dataset.py](../data/patched_unaligned_2d_dataset.py) includes a dataset class that loads pairs of 2d patches from domains A and B from the input stacks specified by the path `--dataroot /path/to/data` which contains the folders `trainA` and `trainB`. This dataset is only used during training of 2d models.
* [patched_unaligned_3d_dataset.py](../data/patched_unaligned_3d_dataset.py) includes a dataset class that loads pairs of 3d patches from domains A and B from the input stacks specified by the path `--dataroot /path/to/data` which contains the folders `trainA` and `trainB`. This dataset is only used during training of 3d models.

[models](../models) directory contains modules related to objective functions, optimizations, and network architectures. To add a custom model class called `dummy`, you need to add a file called `dummy_model.py` and define a subclass `DummyModel` inherited from `BaseModel`. You need to implement four functions: `__init__` (initialize the class; you need to first call `BaseModel.__init__(self, opt)`), `set_input` (unpack data from dataset and apply preprocessing), `forward` (generate intermediate results), `optimize_parameters` (calculate loss, gradients, and update network weights), and optionally `modify_commandline_options` (add model-specific options and set default options). Now you can use the model class by specifying flag `--model dummy`. See our template model [class](../models/template_model.py) for an example.  Below we explain each file in details.

* [\_\_init\_\_.py](../models/__init__.py)  implements the interface between this package and training and test scripts.  `train.py` and `test.py` call `from models import create_model` and `model = create_model(opt)` to create a model given the option `opt`. You also need to call `model.setup(opt)` to properly initialize the model.
* [base_model.py](../models/base_model.py) implements an abstract base class ([ABC](https://docs.python.org/3/library/abc.html)) for models. It also includes commonly used helper functions (e.g., `setup`, `test`, `update_learning_rate`, `save_networks`, `load_networks`), which can be later used in subclasses.
* [cycle_gan_model.py](../models/cycle_gan_model.py) implements the CycleGAN [model](https://junyanz.github.io/CycleGAN/), for learning image-to-image translation without paired data. By default, it uses a `--netG resnet_9blocks` ResNet generator, a `--netD basic` discriminator (PatchGAN  introduced by pix2pix), and a least-square GANs [objective](https://arxiv.org/abs/1611.04076) (`--gan_mode lsgan`).
* [networks_2d.py](../models/networks_2d.py) module implements 2d network architectures (both generators and discriminators), as well as normalization layers, initialization methods, optimization scheduler (i.e., learning rate policy), and GAN objective function (`vanilla`, `lsgan`, `wgangp`).
* [networks_3d.py](../models/networks_3d.py) module implements 3d network architectures (both generators and discriminators), as well as normalization layers, initialization methods, optimization scheduler (i.e., learning rate policy), and GAN objective function (`vanilla`, `lsgan`, `wgangp`).
* [SSIM.py](../models/SSIM.py) module implements the structural similarity metric in 2d and 3d, as published by [https://github.com/jinh0park/pytorch-ssim-3D/tree/master](https://github.com/jinh0park/pytorch-ssim-3D/tree/master)
* [template_model.py](../models/template_model.py) provides a model template with detailed documentation. Check out this file if you plan to implement your own model.
* [test_model.py](../models/test_model.py) implements a model that can be used to generate CycleGAN results for only one direction. This model will automatically set `--dataset_mode patched_2d`, `patched_3d` or `patched_2_5d`, which only loads the images from one set. See the test [instruction](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix#apply-a-pre-trained-model-cyclegan) for more details.


[options](../options) directory includes our option modules: training options, test options, and basic options (used in both training and test). `TrainOptions` and `TestOptions` are both subclasses of `BaseOptions`. They will reuse the options defined in `BaseOptions`.
* [\_\_init\_\_.py](../options/__init__.py)  is required to make Python treat the directory `options` as containing packages,
* [base_options.py](../options/base_options.py) includes options that are used in both training and test. It also implements a few helper functions such as parsing, printing, and saving the options. It also gathers additional options defined in `modify_commandline_options` functions in both dataset class and model class.
* [train_options.py](../options/train_options.py) includes options that are only used during training time.
* [test_options.py](../options/test_options.py) includes options that are only used during test time.


[util](../util) directory includes a miscellaneous collection of useful helper functions.
* [\_\_init\_\_.py](../util/__init__.py) is required to make Python treat the directory `util` as containing packages,
* [fid_score.py](../util/fid_score.py) implements the FID metric for evaluation of model checkpoints, in [fid_analysis.py](../fid_analysis.py). Adapted with some changes from [https://github.com/mseitzer/pytorch-fid](https://github.com/mseitzer/pytorch-fid)
* [image_pool.py](../util/image_pool.py) implements an image buffer that stores previously generated images. This buffer enables us to update discriminators using a history of generated images rather than the ones produced by the latest generators. The original idea was discussed in this [paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Shrivastava_Learning_From_Simulated_CVPR_2017_paper.pdf). The size of the buffer is controlled by the flag `--pool_size`.
* [util.py](../util/util.py) consists of simple helper functions such as `tensor2im` (convert a tensor array to a numpy image array), `adjust_patch_size` (changes the patch size according to the backbone used for training), and `mkdirs` (create multiple directories).
* [visualizer.py](../util/visualizer.py) includes functions that allow the visualisation of images, plots of the losses and metrics of GPU utilisation during training using wandb.